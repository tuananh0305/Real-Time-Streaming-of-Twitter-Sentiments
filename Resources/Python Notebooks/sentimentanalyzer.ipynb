{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4290f21d",
   "metadata": {
    "id": "4290f21d"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "import wget\n",
    "from pyspark.ml.feature import Bucketizer,RegexTokenizer,StopWordsRemover,CountVectorizer,IDF\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline,PipelineModel\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d37dc26",
   "metadata": {
    "id": "6d37dc26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/homebrew/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/daoanhtuan/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/daoanhtuan/.ivy2/jars\n",
      "org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency\n",
      "org.apache.spark#spark-avro_2.12 added as a dependency\n",
      "org.mongodb.spark#mongo-spark-connector_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-96986f73-2a21-438e-abef-c0fc2fb9ec77;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.spark#spark-sql-kafka-0-10_2.12;3.0.0 in central\n",
      "\tfound org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.0.0 in central\n",
      "\tfound org.apache.kafka#kafka-clients;2.4.1 in central\n",
      "\tfound com.github.luben#zstd-jni;1.4.4-3 in central\n",
      "\tfound org.lz4#lz4-java;1.7.1 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.7.5 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.30 in central\n",
      "\tfound org.spark-project.spark#unused;1.0.0 in central\n",
      "\tfound org.apache.commons#commons-pool2;2.6.2 in central\n",
      "\tfound org.apache.spark#spark-avro_2.12;3.0.0 in central\n",
      "\tfound org.mongodb.spark#mongo-spark-connector_2.12;3.0.0 in central\n",
      "\tfound org.mongodb#mongodb-driver-sync;4.0.5 in central\n",
      "\tfound org.mongodb#bson;4.0.5 in central\n",
      "\tfound org.mongodb#mongodb-driver-core;4.0.5 in central\n",
      ":: resolution report :: resolve 912ms :: artifacts dl 36ms\n",
      "\t:: modules in use:\n",
      "\tcom.github.luben#zstd-jni;1.4.4-3 from central in [default]\n",
      "\torg.apache.commons#commons-pool2;2.6.2 from central in [default]\n",
      "\torg.apache.kafka#kafka-clients;2.4.1 from central in [default]\n",
      "\torg.apache.spark#spark-avro_2.12;3.0.0 from central in [default]\n",
      "\torg.apache.spark#spark-sql-kafka-0-10_2.12;3.0.0 from central in [default]\n",
      "\torg.apache.spark#spark-token-provider-kafka-0-10_2.12;3.0.0 from central in [default]\n",
      "\torg.lz4#lz4-java;1.7.1 from central in [default]\n",
      "\torg.mongodb#bson;4.0.5 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-core;4.0.5 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-sync;4.0.5 from central in [default]\n",
      "\torg.mongodb.spark#mongo-spark-connector_2.12;3.0.0 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.30 from central in [default]\n",
      "\torg.spark-project.spark#unused;1.0.0 from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.7.5 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   14  |   0   |   0   |   0   ||   14  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-96986f73-2a21-438e-abef-c0fc2fb9ec77\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 14 already retrieved (0kB/19ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/05 22:53:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "#Spark Session creation configured to interact with Kfka and MongoDB\n",
    "spark = SparkSession.builder.appName(\"pyspark-notebook\").\\\n",
    "config(\"spark.jars.packages\",\"org.apache.spark:spark-sql-kafka-0-10_2.12:3.0.0,org.apache.spark:spark-avro_2.12:3.0.0,org.mongodb.spark:mongo-spark-connector_2.12:3.0.0\").\\\n",
    "config(\"spark.mongodb.input.uri\",\"mongodb://docker_mongo_1:27017/twitter_db.tweets\").\\\n",
    "config(\"spark.mongodb.output.uri\",\"mongodb://docker_mongo_1:27017/twitter_db.tweets\").\\\n",
    "getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "394f0e2c",
   "metadata": {
    "id": "394f0e2c"
   },
   "outputs": [],
   "source": [
    "#spark.read.json(\"reviews_Sports_and_Outdoors_5.json.gz\").show(35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e7b9b96",
   "metadata": {
    "id": "0e7b9b96",
    "outputId": "716381d8-0374-4219-a493-615e0efae504"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "296337"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Download dataset if not exists and read it as spark dataframe\n",
    "try:\n",
    "    df0 = spark.read.json(\"reviews_Sports_and_Outdoors_5.json.gz\")\n",
    "except Exception as e:\n",
    "    url = \"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Sports_and_Outdoors_5.json.gz\"\n",
    "    wget.download(url)\n",
    "    df0 = spark.read.json(\"reviews_Sports_and_Outdoors_5.json.gz\")\n",
    "\n",
    "df = df0.withColumn(\"text\",concat(col(\"summary\"), lit(\" \"),col(\"reviewText\")))\\\n",
    " .drop(\"helpful\")\\\n",
    " .drop(\"reviewerID\")\\\n",
    " .drop(\"reviewerName\")\\\n",
    " .drop(\"reviewTime\")\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "111b66c2",
   "metadata": {
    "id": "111b66c2",
    "outputId": "a9c28e07-4cfd-418f-b54c-53ee86a7bc36"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[Stage 4:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|           overall|\n",
      "+-------+------------------+\n",
      "|  count|            296337|\n",
      "|   mean| 4.393450699710128|\n",
      "| stddev|0.9869053992908551|\n",
      "|    min|               1.0|\n",
      "|    max|               5.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.describe(\"overall\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91bdffd0",
   "metadata": {
    "id": "91bdffd0",
    "outputId": "9927373e-5fef-4870-dbe4-f06362330b5f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[Stage 7:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+------+\n",
      "|overall|label| count|\n",
      "+-------+-----+------+\n",
      "|    2.0|  0.0| 10204|\n",
      "|    5.0|  1.0|188208|\n",
      "|    1.0|  0.0|  9045|\n",
      "|    4.0|  1.0| 64809|\n",
      "+-------+-----+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Bucketize data and create labels 0 if overall rating is in (1.0,2.0), otherwise 1\n",
    "df1 = df.filter(\"overall !=3\")\n",
    "\n",
    "splits = [-float(\"inf\"), 4.0, float(\"inf\")]\n",
    "\n",
    "bucketizer = Bucketizer(splits=splits, inputCol=\"overall\", outputCol=\"label\")\n",
    "\n",
    "df2= bucketizer.transform(df1)\n",
    "\n",
    "df2.groupBy(\"overall\",\"label\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bce2dc6",
   "metadata": {
    "id": "0bce2dc6",
    "outputId": "75c6f1e2-9115-40c8-f8e7-911c8d911763"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[Stage 10:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  0.0|19249|\n",
      "|  1.0|25224|\n",
      "+-----+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#take sample to create train and test dataset\n",
    "fractions = {1.0 : .1, 0.0 : 1.0}\n",
    "df3 = df2.stat.sampleBy(\"label\", fractions, 36)\n",
    "df3.groupBy(\"label\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d27c2f55",
   "metadata": {
    "id": "d27c2f55"
   },
   "outputs": [],
   "source": [
    "#Split data as 80-20% Train and Test dataset\n",
    "splitSeed = 5043\n",
    "trainingData, testData = df3.randomSplit([0.8, 0.2], splitSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09a57ba9",
   "metadata": {
    "id": "09a57ba9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/05 22:53:32 WARN StopWordsRemover: Default locale set was [en_FR]; however, it was not found in available locales in JVM, falling back to en_US locale. Set param `locale` in order to respect another locale.\n"
     ]
    }
   ],
   "source": [
    "#Tokenize \n",
    "tokenizer = RegexTokenizer(inputCol=\"text\",outputCol=\"reviewTokensUf\",pattern=\"\\\\s+|[,.()\\\"]\")\n",
    "\n",
    "remover = StopWordsRemover(stopWords=StopWordsRemover.loadDefaultStopWords(\"english\"),inputCol=\"reviewTokensUf\",outputCol=\"reviewTokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "074e54d7",
   "metadata": {
    "id": "074e54d7"
   },
   "outputs": [],
   "source": [
    "#converts word documents to vectors of token counts\n",
    "cv = CountVectorizer(inputCol=\"reviewTokens\",outputCol=\"cv\",vocabSize=296337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d009b27",
   "metadata": {
    "id": "8d009b27"
   },
   "outputs": [],
   "source": [
    "#IDF model\n",
    "idf = IDF(inputCol=\"cv\",outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c753c97c",
   "metadata": {
    "id": "c753c97c"
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(maxIter=100,regParam=0.02,elasticNetParam=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b49b029a",
   "metadata": {
    "id": "b49b029a"
   },
   "outputs": [],
   "source": [
    "#Creates a pipeline\n",
    "steps =  [tokenizer, remover, cv, idf,lr]\n",
    "pipeline = Pipeline(stages=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8b9c448",
   "metadata": {
    "id": "d8b9c448"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/05 22:53:52 WARN DAGScheduler: Broadcasting large task binary with size 1997.2 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/05 22:53:57 WARN DAGScheduler: Broadcasting large task binary with size 1998.7 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[Stage 19:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/05 22:54:02 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "22/10/05 22:54:02 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n",
      "22/10/05 22:54:02 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "22/10/05 22:54:02 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/05 22:54:02 WARN DAGScheduler: Broadcasting large task binary with size 1998.7 KiB\n",
      "22/10/05 22:54:02 WARN DAGScheduler: Broadcasting large task binary with size 1998.7 KiB\n",
      "22/10/05 22:54:02 WARN DAGScheduler: Broadcasting large task binary with size 1998.7 KiB\n",
      "22/10/05 22:54:03 WARN DAGScheduler: Broadcasting large task binary with size 1998.7 KiB\n",
      "22/10/05 22:54:03 WARN DAGScheduler: Broadcasting large task binary with size 1998.7 KiB\n",
      "22/10/05 22:54:03 WARN DAGScheduler: Broadcasting large task binary with size 1998.7 KiB\n",
      "22/10/05 22:54:03 WARN DAGScheduler: Broadcasting large task binary with size 1998.7 KiB\n",
      "22/10/05 22:54:03 WARN DAGScheduler: Broadcasting large task binary with size 1998.7 KiB\n",
      "22/10/05 22:54:04 WARN DAGScheduler: Broadcasting large task binary with size 1998.7 KiB\n",
      "22/10/05 22:54:04 WARN DAGScheduler: Broadcasting large task binary with size 1998.7 KiB\n",
      "22/10/05 22:54:04 WARN DAGScheduler: Broadcasting large task binary with size 1998.7 KiB\n",
      "22/10/05 22:54:04 WARN DAGScheduler: Broadcasting large task binary with size 1998.7 KiB\n",
      "22/10/05 22:54:04 WARN DAGScheduler: Broadcasting large task binary with size 1998.7 KiB\n",
      "22/10/05 22:54:04 WARN DAGScheduler: Broadcasting large task binary with size 1998.7 KiB\n",
      "22/10/05 22:54:05 WARN DAGScheduler: Broadcasting large task binary with size 1998.7 KiB\n",
      "22/10/05 22:54:05 WARN DAGScheduler: Broadcasting large task binary with size 1998.7 KiB\n",
      "22/10/05 22:54:05 WARN DAGScheduler: Broadcasting large task binary with size 1998.7 KiB\n",
      "22/10/05 22:54:05 WARN DAGScheduler: Broadcasting large task binary with size 1998.7 KiB\n",
      "22/10/05 22:54:05 WARN DAGScheduler: Broadcasting large task binary with size 1998.7 KiB\n",
      "22/10/05 22:54:05 WARN DAGScheduler: Broadcasting large task binary with size 1998.7 KiB\n",
      "22/10/05 22:54:06 WARN DAGScheduler: Broadcasting large task binary with size 1998.7 KiB\n",
      "22/10/05 22:54:06 WARN DAGScheduler: Broadcasting large task binary with size 1998.7 KiB\n",
      "22/10/05 22:54:06 WARN DAGScheduler: Broadcasting large task binary with size 1998.7 KiB\n",
      "22/10/05 22:54:06 WARN DAGScheduler: Broadcasting large task binary with size 1998.7 KiB\n",
      "22/10/05 22:54:06 WARN DAGScheduler: Broadcasting large task binary with size 1998.7 KiB\n",
      "22/10/05 22:54:06 WARN DAGScheduler: Broadcasting large task binary with size 1998.7 KiB\n",
      "22/10/05 22:54:06 WARN DAGScheduler: Broadcasting large task binary with size 1998.7 KiB\n",
      "22/10/05 22:54:07 WARN DAGScheduler: Broadcasting large task binary with size 1998.7 KiB\n",
      "22/10/05 22:54:07 WARN DAGScheduler: Broadcasting large task binary with size 1998.7 KiB\n",
      "22/10/05 22:54:07 WARN DAGScheduler: Broadcasting large task binary with size 1998.7 KiB\n",
      "22/10/05 22:54:07 WARN DAGScheduler: Broadcasting large task binary with size 1998.7 KiB\n",
      "22/10/05 22:54:07 WARN DAGScheduler: Broadcasting large task binary with size 1998.7 KiB\n",
      "22/10/05 22:54:07 WARN DAGScheduler: Broadcasting large task binary with size 1998.7 KiB\n",
      "22/10/05 22:54:07 WARN DAGScheduler: Broadcasting large task binary with size 1998.7 KiB\n",
      "22/10/05 22:54:08 WARN DAGScheduler: Broadcasting large task binary with size 1998.7 KiB\n",
      "22/10/05 22:54:08 WARN DAGScheduler: Broadcasting large task binary with size 1998.7 KiB\n",
      "22/10/05 22:54:08 WARN DAGScheduler: Broadcasting large task binary with size 1998.7 KiB\n",
      "22/10/05 22:54:08 WARN DAGScheduler: Broadcasting large task binary with size 1998.7 KiB\n",
      "22/10/05 22:54:08 WARN DAGScheduler: Broadcasting large task binary with size 1998.7 KiB\n",
      "22/10/05 22:54:08 WARN DAGScheduler: Broadcasting large task binary with size 1998.7 KiB\n",
      "22/10/05 22:54:08 WARN DAGScheduler: Broadcasting large task binary with size 1998.7 KiB\n",
      "22/10/05 22:54:09 WARN DAGScheduler: Broadcasting large task binary with size 1998.7 KiB\n",
      "22/10/05 22:54:09 WARN DAGScheduler: Broadcasting large task binary with size 1998.7 KiB\n"
     ]
    }
   ],
   "source": [
    "model = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3ed06a6",
   "metadata": {
    "id": "c3ed06a6"
   },
   "outputs": [],
   "source": [
    "#collecting all metrics\n",
    "vocabulary = model.stages[2].vocabulary\n",
    "weights = model.stages[-1].coefficients.toArray()\n",
    "weights = [float(weight) for weight in weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9b8a949",
   "metadata": {
    "id": "b9b8a949"
   },
   "outputs": [],
   "source": [
    "schema = StructType([StructField('word', StringType()),\n",
    "                     StructField('weight', FloatType())\n",
    "                     ])\n",
    "cdf = spark.createDataFrame(zip(vocabulary, weights), schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56346b17",
   "metadata": {
    "id": "56346b17",
    "outputId": "4ab8aafe-8635-4531-b456-e25a748aa1b1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[Stage 63:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+\n",
      "|     word|    weight|\n",
      "+---------+----------+\n",
      "|    great|0.58763325|\n",
      "|   thoses|0.32552686|\n",
      "|  perfect| 0.3234427|\n",
      "|     easy|0.26150194|\n",
      "|   highly|0.25427526|\n",
      "|     love|0.23298806|\n",
      "|excellent|0.22146559|\n",
      "|     nice|0.21586911|\n",
      "|     good|0.20863196|\n",
      "|    works|0.20269915|\n",
      "+---------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "cdf.orderBy(desc(\"weight\")).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0dd14bb1",
   "metadata": {
    "id": "0dd14bb1",
    "outputId": "963a9ba5-59d7-462a-e3e6-32f02593522b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+\n",
      "|         word|     weight|\n",
      "+-------------+-----------+\n",
      "|     returned| -0.3884238|\n",
      "|         poor|   -0.33077|\n",
      "|      useless| -0.3029925|\n",
      "|        waste|-0.27847156|\n",
      "|        broke| -0.2696688|\n",
      "|         junk| -0.2493959|\n",
      "|       return|-0.24829988|\n",
      "|disappointing|-0.22996198|\n",
      "|    returning| -0.2170597|\n",
      "| disappointed| -0.2141453|\n",
      "+-------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cdf.orderBy(\"weight\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a35d20a",
   "metadata": {
    "id": "4a35d20a"
   },
   "outputs": [],
   "source": [
    "predictions = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86682040",
   "metadata": {
    "id": "86682040"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/05 22:55:32 WARN DAGScheduler: Broadcasting large task binary with size 2015.4 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "evaluator = BinaryClassificationEvaluator()  \n",
    "areaUnderROC = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d624986",
   "metadata": {
    "id": "7d624986",
    "outputId": "4cf3b71f-5198-45e3-be3d-bc570f222c77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/05 22:55:36 WARN DAGScheduler: Broadcasting large task binary with size 2035.8 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[Stage 74:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+--------------------+--------------------+--------------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|      asin|overall|          reviewText|             summary|unixReviewTime|                text|label|      reviewTokensUf|        reviewTokens|                  cv|            features|       rawPrediction|         probability|prediction|\n",
      "+----------+-------+--------------------+--------------------+--------------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|7245456313|    1.0|I wish I would ha...|Defective - Be Ca...|    1354492800|Defective - Be Ca...|  0.0|[defective, -, be...|[defective, -, ca...|(71899,[0,11,15,1...|(71899,[0,11,15,1...|[1.99664552031553...|[0.88044442899395...|       0.0|\n",
      "|7245456313|    5.0|I bought this ban...|Great product, aw...|    1400112000|Great product, aw...|  1.0|[great, product, ...|[great, product, ...|(71899,[0,1,2,4,5...|(71899,[0,1,2,4,5...|[-3.3010769657795...|[0.03553426148797...|       1.0|\n",
      "|7245456313|    5.0|I used to be a pe...|GREAT product for...|    1304899200|GREAT product for...|  1.0|[great, product, ...|[great, product, ...|(71899,[1,8,16,20...|(71899,[1,8,16,20...|[-1.4400873000922...|[0.19153183000616...|       1.0|\n",
      "|7245456313|    5.0|My arms are burni...|Love Love Love th...|    1358985600|Love Love Love th...|  1.0|[love, love, love...|[love, love, love...|(71899,[6,10,13,3...|(71899,[6,10,13,3...|[-3.2228409709715...|[0.03831516650524...|       1.0|\n",
      "|B00000IURU|    5.0|Use this at pre s...|Toddlers love thi...|    1400803200|Toddlers love thi...|  1.0|[toddlers, love, ...|[toddlers, love, ...|(71899,[4,18,38,3...|(71899,[4,18,38,3...|[-0.6913545500887...|[0.33373181460849...|       1.0|\n",
      "|B00000J6JO|    1.0|As I write this r...|Very Cheaply made...|    1369699200|Very Cheaply made...|  0.0|[very, cheaply, m...|[cheaply, made, p...|(71899,[4,8,14,18...|(71899,[4,8,14,18...|[1.19645206355169...|[0.76789302410903...|       0.0|\n",
      "|B00000J6JO|    4.0|I saw a lot of ne...|Really good gift ...|    1401148800|Really good gift ...|  1.0|[really, good, gi...|[really, good, gi...|(71899,[0,2,3,4,5...|(71899,[0,2,3,4,5...|[-0.4116351210268...|[0.39852011468548...|       1.0|\n",
      "|B0000224UE|    5.0|I was given this ...|   Always by my side|    1361404800|Always by my side...|  1.0|[always, by, my, ...|[always, side, gi...|(71899,[0,4,5,6,1...|(71899,[0,4,5,6,1...|[0.07026414796384...|[0.51755881352291...|       0.0|\n",
      "|B0000224UE|    5.0|The victor inbox ...|Victorinox Multi-...|    1361923200|Victorinox Multi-...|  1.0|[victorinox, mult...|[victorinox, mult...|(71899,[6,14,16,1...|(71899,[6,14,16,1...|[-1.1410051971434...|[0.24213585339733...|       1.0|\n",
      "|B000030056|    1.0|Cheap product!  W...|       Cheap product|    1309564800|Cheap product Che...|  0.0|[cheap, product, ...|[cheap, product, ...|(71899,[4,8,14,17...|(71899,[4,8,14,17...|[1.16344346505709...|[0.76195784722352...|       0.0|\n",
      "|B00003CYPK|    5.0|Trac Ball is just...|One of the best b...|    1226188800|One of the best b...|  1.0|[one, of, the, be...|[one, best, backy...|(71899,[0,3,5,13,...|(71899,[0,3,5,13,...|[-3.1076777122085...|[0.04279166544420...|       1.0|\n",
      "|B00004NKIQ|    5.0|This net is great...|excellent net for...|    1341532800|excellent net for...|  1.0|[excellent, net, ...|[excellent, net, ...|(71899,[6,14,21,2...|(71899,[6,14,21,2...|[-2.1942508396654...|[0.10026795492396...|       1.0|\n",
      "|B00004SQM7|    2.0|This must be more...|          Didn't Fit|    1307404800|Didn't Fit This m...|  0.0|[didn't, fit, thi...|[fit, must, ideal...|(71899,[9,39,41,4...|(71899,[9,39,41,4...|[2.05945975308304...|[0.88689998995137...|       0.0|\n",
      "|B00004SQM9|    1.0|This lock jammed ...|            Not good|    1234656000|Not good This loc...|  0.0|[not, good, this,...|[good, lock, jamm...|(71899,[2,60,113,...|(71899,[2,60,113,...|[0.27829862678740...|[0.56912906036934...|       0.0|\n",
      "|B00004SQM9|    2.0|Works great on fi...|doesn't work well...|    1272326400|doesn't work well...|  0.0|[doesn't, work, w...|[work, well, leve...|(71899,[1,5,6,11,...|(71899,[1,5,6,11,...|[-0.9750281648226...|[0.27387941757984...|       1.0|\n",
      "|B00004SQM9|    4.0|This is a great a...|Works for multipl...|    1369180800|Works for multipl...|  1.0|[works, for, mult...|[works, multiple,...|(71899,[0,1,5,15,...|(71899,[0,1,5,15,...|[-1.4518698832994...|[0.18971395596011...|       1.0|\n",
      "|B00004SQM9|    5.0|I like the combin...|Very good trigger...|    1342051200|Very good trigger...|  1.0|[very, good, trig...|[good, trigger, l...|(71899,[2,3,26,44...|(71899,[2,3,26,44...|[-0.9615637689280...|[0.27656521155078...|       1.0|\n",
      "|B00004T1JW|    5.0|These bases are v...|Very nice set of ...|    1357084800|Very nice set of ...|  1.0|[very, nice, set,...|[nice, set, bases...|(71899,[6,13,15,1...|(71899,[6,13,15,1...|[-1.5148423420841...|[0.18022226675129...|       1.0|\n",
      "|B00004THDC|    4.0|Excellent optics....|    Excellent Optics|    1386288000|Excellent Optics ...|  1.0|[excellent, optic...|[excellent, optic...|(71899,[6,20,22,2...|(71899,[6,20,22,2...|[-2.9582924508042...|[0.04934604733758...|       1.0|\n",
      "|B00004TQ2P|    5.0|Good for kids and...|  Good for my nephew|    1382832000|Good for my nephe...|  1.0|[good, for, my, n...|[good, nephew, go...|(71899,[2,31,47,7...|(71899,[2,31,47,7...|[-0.5040736704241...|[0.37658381978212...|       1.0|\n",
      "+----------+-------+--------------------+--------------------+--------------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f3fb74b",
   "metadata": {
    "id": "8f3fb74b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/05 22:55:55 WARN DAGScheduler: Broadcasting large task binary with size 2012.2 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/05 22:55:58 WARN DAGScheduler: Broadcasting large task binary with size 2012.4 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/05 22:56:03 WARN DAGScheduler: Broadcasting large task binary with size 2012.2 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/05 22:56:06 WARN DAGScheduler: Broadcasting large task binary with size 2012.4 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/05 22:56:08 WARN DAGScheduler: Broadcasting large task binary with size 2012.5 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/05 22:56:11 WARN DAGScheduler: Broadcasting large task binary with size 2012.5 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/05 22:56:13 WARN DAGScheduler: Broadcasting large task binary with size 2012.6 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/05 22:56:15 WARN DAGScheduler: Broadcasting large task binary with size 2012.6 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#model evaluation\n",
    "lp = predictions.select(\"label\", \"prediction\")\n",
    "counttotal = predictions.count()\n",
    "correct = lp.filter(col(\"label\") == col(\"prediction\")).count()\n",
    "wrong = lp.filter(~(col(\"label\") == col(\"prediction\"))).count()\n",
    "ratioWrong = float(wrong) / float(counttotal)\n",
    "lp = predictions.select(  \"prediction\",\"label\")\n",
    "counttotal = float(predictions.count())\n",
    "correct = lp.filter(col(\"label\") == col(\"prediction\")).count()\n",
    "wrong = lp.filter(\"label != prediction\").count()\n",
    "ratioWrong=wrong/counttotal\n",
    "ratioCorrect=correct/counttotal\n",
    "trueneg =( lp.filter(col(\"label\") == 0.0).filter(col(\"label\") == col(\"prediction\")).count()) /counttotal\n",
    "truepos = (lp.filter(col(\"label\") == 1.0).filter(col(\"label\") == col(\"prediction\")).count())/counttotal\n",
    "falseneg = (lp.filter(col(\"label\") == 0.0).filter(~(col(\"label\") == col(\"prediction\"))).count())/counttotal\n",
    "falsepos = (lp.filter(col(\"label\") == 1.0).filter(~(col(\"label\") == col(\"prediction\"))).count())/counttotal\n",
    "\n",
    "precision= truepos / (truepos + falsepos)\n",
    "recall= truepos / (truepos + falseneg)\n",
    "#fmeasure= 2  precision  recall / (precision + recall)\n",
    "accuracy=(truepos + trueneg) / (truepos + trueneg + falsepos + falseneg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7c3824f",
   "metadata": {
    "id": "b7c3824f",
    "outputId": "632ee324-c3f8-4519-f7b0-be3dc85f63e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counttotal   : 9003.0\n",
      "correct      : 7776\n",
      "wrong        : 1227\n",
      "ratioWrong   : 0.13628790403198934\n",
      "ratioCorrect : 0.8637120959680107\n",
      "truen        : 0.3361101854937243\n",
      "truep        : 0.5276019104742864\n",
      "falsen       : 0.08863712095968011\n",
      "falsep       : 0.04765078307230923\n",
      "precision    : 0.9171654759606103\n",
      "recall       : 0.8561643835616438\n",
      "accuracy     : 0.8637120959680107\n"
     ]
    }
   ],
   "source": [
    "print('counttotal   :', counttotal     )\n",
    "print('correct      :', correct        )\n",
    "print('wrong        :', wrong          )\n",
    "print('ratioWrong   :', ratioWrong     )\n",
    "print('ratioCorrect :', ratioCorrect   )\n",
    "print('truen        :', trueneg          )\n",
    "print('truep        :', truepos          )\n",
    "print('falsen       :', falseneg         )\n",
    "print('falsep       :', falsepos         )\n",
    "print('precision    :', precision      )\n",
    "print('recall       :', recall         )\n",
    "#print('fmeasure     :', fmeasure       )\n",
    "print('accuracy     :', accuracy       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea2f523d",
   "metadata": {
    "id": "ea2f523d",
    "outputId": "c892f587-d3eb-4439-dd16-177052de438e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/05 22:56:18 WARN DAGScheduler: Broadcasting large task binary with size 2026.1 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[Stage 105:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------+----------+\n",
      "|             summary|        reviewTokens|overall|prediction|\n",
      "+--------------------+--------------------+-------+----------+\n",
      "|Buyer Beware - Yo...|[buyer, beware, -...|    2.0|       0.0|\n",
      "|Awful Phone and T...|[awful, phone, te...|    1.0|       0.0|\n",
      "|DO NOT BUY HERE I...|[buy, need, custo...|    1.0|       0.0|\n",
      "|                JUNK|[junk, well, rece...|    1.0|       0.0|\n",
      "|Poor 3-9x40 Hamme...|[poor, 3-9x40, ha...|    1.0|       0.0|\n",
      "+--------------------+--------------------+-------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions.filter(col(\"prediction\") == 0.0)\\\n",
    ".select(\"summary\",\"reviewTokens\",\"overall\",\"prediction\")\\\n",
    ".orderBy(desc(\"rawPrediction\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67f67c23",
   "metadata": {
    "id": "67f67c23",
    "outputId": "10f5971b-77a4-495c-8207-403a13154f5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/05 22:56:21 WARN DAGScheduler: Broadcasting large task binary with size 2026.0 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[Stage 106:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------+----------+\n",
      "|             summary|        reviewTokens|overall|prediction|\n",
      "+--------------------+--------------------+-------+----------+\n",
      "|My DROID Story an...|[droid, story, co...|    5.0|       1.0|\n",
      "| great trucker phone|[great, trucker, ...|    5.0|       1.0|\n",
      "|    Favorite EDC Bag|[favorite, edc, b...|    4.0|       1.0|\n",
      "|One of My Favorit...|[one, favorites!!...|    4.0|       1.0|\n",
      "|Best Hopper I've ...|[best, hopper, us...|    4.0|       1.0|\n",
      "+--------------------+--------------------+-------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions.filter(col(\"prediction\")== 1.0)\\\n",
    ".select(\"summary\",\"reviewTokens\",\"overall\",\"prediction\")\\\n",
    ".orderBy(\"rawPrediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46797c12",
   "metadata": {
    "id": "46797c12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/05 22:56:27 WARN TaskSetManager: Stage 111 contains a task of very large size (1382 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/05 22:56:29 WARN TaskSetManager: Stage 115 contains a task of very large size (1151 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[Stage 121:>                                                        (0 + 1) / 1]\r\n",
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dir = \"sentiment/\"\n",
    "model.write().overwrite().save(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33b356fa",
   "metadata": {
    "id": "33b356fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/05 22:58:07 WARN StopWordsRemover: Default locale set was [en_FR]; however, it was not found in available locales in JVM, falling back to en_US locale. Set param `locale` in order to respect another locale.\n",
      "22/10/05 22:58:09 WARN StopWordsRemover: Default locale set was [en_FR]; however, it was not found in available locales in JVM, falling back to en_US locale. Set param `locale` in order to respect another locale.\n"
     ]
    }
   ],
   "source": [
    "dir = \"sentiment/\"\n",
    "model = PipelineModel.load(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05251f93",
   "metadata": {
    "id": "05251f93",
    "outputId": "f1e2ce9d-c8a2-4089-f51e-efb6035c56ba"
   },
   "outputs": [],
   "source": [
    "df = spark.read.format(\"mongo\").load()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc22ffb8",
   "metadata": {
    "id": "fc22ffb8",
    "outputId": "bcfc57d0-d04a-4e88-b453-c00665c792eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------------------------------+----------+\n",
      "|text                                                                                                                         |prediction|\n",
      "+-----------------------------------------------------------------------------------------------------------------------------+----------+\n",
      "| done &lt;3\n",
      "I Ten lub Jungwoo &lt;33                                                                                         |1.0       |\n",
      "| Well done you 👍👍👍                                                                                                        |1.0       |\n",
      "| ElbeDay 25th April 1945                                                                                                     |1.0       |\n",
      "|We letting them titties tittie today 🤪 What’s a bra? Oooooh okay!                                                           |1.0       |\n",
      "|  \"Self-care isn't always baths and chocolate (sometimes it will be), but it is an intentional stance to do what you need…   |1.0       |\n",
      "| literally my first thought                                                                                                  |0.0       |\n",
      "|  ⬇️⬇️⬇️⬇️⬇️⬇️⬇️⬇️⬇️⬇️⬇️⬇️⬇️⬇️⬇️⬇️⬇️⬇️🐣     ☘️EASTER          \n",
      "           PROMOTION                                      🐣…|1.0       |\n",
      "|  YOOOO THE CRYING OBSIDIAN EFFECT?? WHO CODED THAT SHEEEEEEESH /dsmp                                                        |1.0       |\n",
      "|  The shoe signing         The reaction 🥺                                                                                   |1.0       |\n",
      "|  I stand with bravery MakeSchoolASaferPlace                                                                                 |1.0       |\n",
      "| SECOND WOOOH                                                                                                                |1.0       |\n",
      "|  don’t u think i need a spanking?                                                                                           |1.0       |\n",
      "|im so sorry Cate and Sandy but i would pick Sarah, Pedro and Amanda ✨💕                                                      |0.0       |\n",
      "|   It was 3 hours. He was carefully teach us and not rushing. Very patience and seriously want to teach us the da…           |1.0       |\n",
      "|  Nadal Trophy celebration !! \n",
      "BCNOpenBS                                                                                     |1.0       |\n",
      "|Don't let me go                                                                                                              |1.0       |\n",
      "|everytime my grandmother tells me having short hair makes me look ugly I'm tempted to re shave my head out of spite          |0.0       |\n",
      "|  vote for \n",
      "\n",
      "tzuyu\n",
      "fanplus\n",
      "starplay\n",
      "choeaedol(and TWICE as a group) \n",
      "\n",
      "dahyun\n",
      "starpic (VOTING ENDS IN THREE DAYS AND THE GAP… |1.0       |\n",
      "|one person unfollowed me // automatically checked by                                                                         |1.0       |\n",
      "|  ⚠️everyone NEEDS to learn this self-defense trick, it blew my mind 🤯                                                      |1.0       |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"mongo\").load().select(\"timestamp_ms\",\"text\")\n",
    "splits = [-float(\"inf\"), 0, float(\"inf\")]\n",
    "#bucketizer = Bucketizer(inputCol=\"timestamp_ms\",outputCol=\"sentiment\",splits=splits)\n",
    "\n",
    "#df5= bucketizer.transform(df)\n",
    "predictions = model.transform(df)\n",
    "predictions.select('text','prediction').show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "sentimentanalyzer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
